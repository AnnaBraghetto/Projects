{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1574281844869,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "-xHm9TJ70uQE",
    "outputId": "a3d27bc7-405c-4472-8ee3-d40b04ecac8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I use cuda: False\n",
      "I perform the random search: False\n",
      "I perform the final training: False\n",
      "I compute the accuracy: False\n",
      "I compute the receptive fields: False\n",
      "I perform the feature visualization: False\n"
     ]
    }
   ],
   "source": [
    "#IMPORT THE REQUIRED PACKAGES\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#GPU\n",
    "\n",
    "useCuda = False\n",
    "if torch.cuda.is_available():\n",
    "  useCuda = True\n",
    "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "print('I use cuda:',useCuda)\n",
    "\n",
    "#processes\n",
    "\n",
    "RC = False\n",
    "print('I perform the random search:',RC)\n",
    "\n",
    "Final = False\n",
    "print('I perform the final training:',Final)\n",
    "\n",
    "Acc = False\n",
    "print('I compute the accuracy:',Acc)\n",
    "\n",
    "RF = False\n",
    "print('I compute the receptive fields:',RF)\n",
    "\n",
    "FV = False\n",
    "print('I perform the feature visualization:',FV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3103,
     "status": "ok",
     "timestamp": 1574281845940,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "lx4SN6p50uQI",
    "outputId": "203472be-3aec-4999-88f2-fd1cd10bd593"
   },
   "outputs": [],
   "source": [
    "#READ THE DATA\n",
    "mat = sio.loadmat(\"./MNIST.mat\")\n",
    "\n",
    "X = mat['input_images']\n",
    "Y = mat['output_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3099,
     "status": "ok",
     "timestamp": 1574281845942,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "ZydmhDyZ0uQK",
    "outputId": "2194afb4-2739-4dc1-f556-50fab4393005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training and test sets have shapes:\n",
      "Shape of X_train: (48000, 784)\n",
      "Shape of Y_train: (48000, 1)\n",
      "Shape of X_test: (12000, 784)\n",
      "Shape of Y_test: (12000, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DIVIDE INTO TRAIN AND TEST\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=1234)\n",
    "\n",
    "print('The training and test sets have shapes:')\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of Y_train:', Y_train.shape)\n",
    "print('Shape of X_test:', X_test.shape)\n",
    "print('Shape of Y_test:', Y_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZ34pMWJ0uQO"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE NETOWRK\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, LN):\n",
    "        super(Net, self).__init__()\n",
    "        #number of hidden layers\n",
    "        numberL = len(LN)\n",
    "        self.network = nn.Sequential()\n",
    "        #first layer\n",
    "        self.network.add_module('net1',nn.Linear(in_features=784, out_features=LN[0]))  \n",
    "        self.network.add_module('act1',nn.LeakyReLU())   \n",
    "   \n",
    "        #hidden layers\n",
    "        j=2\n",
    "        for i in range(numberL-1):\n",
    "            name = 'net'+str(i+2)\n",
    "            self.network.add_module(name,nn.Linear(in_features=LN[i], out_features=LN[i+1]))\n",
    "            name = 'act'+str(i+2) \n",
    "            self.network.add_module(name,nn.LeakyReLU())\n",
    "            j += 1\n",
    "\n",
    "        name = 'net'+str(j)\n",
    "        self.network.add_module(name,nn.Linear(in_features=LN[-1], out_features=10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #compute up the last layer\n",
    "        out = self.network(x)\n",
    "        return out\n",
    "\n",
    "    def output(self, x):\n",
    "        #returns the class \n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x)\n",
    "            out = nn.functional.softmax(out,dim=1)\n",
    "            _, predicted = torch.max(out, 1)\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKxLvh3V0uQR"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE TRAINING\n",
    "\n",
    "def Printlr(opt):\n",
    "    for p in opt.param_groups:\n",
    "        return p['lr']\n",
    "\n",
    "def Training(net, opt, gamma, cool, num_epochs, Xt, Yt, Xv, Yv, verbose):\n",
    "\n",
    "    #optimizer\n",
    "    optimizer = opt\n",
    "    #scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',factor=gamma, patience=50, cooldown=cool, min_lr=1e-6, threshold=1e-10, verbose=verbose)\n",
    "\n",
    "    #train and test loss\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "\n",
    "    #define the loss function (the most used are already implemented in pytorch, see the doc!)\n",
    "    lossfn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if useCuda:\n",
    "        torch.cuda.empty_cache()\n",
    "        net.cuda()\n",
    "        lossfn.cuda()\n",
    "        Xt = Xt.cuda()\n",
    "        Yt = Yt.cuda()\n",
    "        Xv = Xv.cuda()\n",
    "        Yv = Yv.cuda()\n",
    "\n",
    "    for num_ep in range(num_epochs):\n",
    "\n",
    "        #update\n",
    "        net.train()\n",
    "\n",
    "        # IMPORTANT! zeroes the gradient buffers of all parameters\n",
    "        optimizer.zero_grad()    \n",
    "        # Forward pass\n",
    "        out = net(Xt)\n",
    "        # Evaluate loss\n",
    "        loss = lossfn(out, Yt)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        #optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        #evaluate network\n",
    "        net.eval()\n",
    "        with torch.no_grad(): # Avoid tracking the gradients (much faster!)\n",
    "            out = net(Xv)\n",
    "            val_loss = lossfn(out, Yv)\n",
    "\n",
    "        #compute the loss\n",
    "        train_loss_log.append(float(loss.item()))\n",
    "        val_loss_log.append(float(val_loss.item()))\n",
    "\n",
    "        #scheduler step\n",
    "        scheduler.step(val_loss_log[-1])\n",
    "\n",
    "        if verbose:\n",
    "            if (num_ep % 99 == 0):\n",
    "                print('Epoch %d  - lr: %.6f -  Train loss: %.6f - Val loss: %.6f' % (num_ep + 1, Printlr(optimizer), float(loss.item()), float(val_loss.item())))\n",
    "\n",
    "        #Early stopping\n",
    "        \n",
    "        #check the patience\n",
    "        stop=False\n",
    "        if num_ep > 2000:\n",
    "            #check the improvement on the validation loss\n",
    "            check1 = 0\n",
    "            check2 = 0\n",
    "            for es in range(0,80,5):\n",
    "                if abs(val_loss_log[num_ep-2-es] - val_loss_log[num_ep-1-es]) < 1e-7: check1 += 1\n",
    "            for es in range(200):\n",
    "                if val_loss_log[num_ep-2-es] - val_loss_log[num_ep-1-es] < 0 : check2 += 1\n",
    "                \n",
    "            if check1 == 16 or check2 > 180: stop=True\n",
    "\n",
    "        if stop:\n",
    "            print('Stop due to early stopping')\n",
    "            break\n",
    "\n",
    "\n",
    "    return train_loss_log, val_loss_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQB5QTgw0uQT"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE RANDOM SEARCH\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def RandomSearch(RC,model,parameters,cases,X_train,Y_train,cv,epochs=1000,verbose=False):\n",
    "\n",
    "    if RC:\n",
    "        \n",
    "        #convert the keys of the parameter dictionary into a list\n",
    "        NamePar = list(parameters.keys())\n",
    "        \n",
    "        #build the combination of parameters\n",
    "        Combinations = []\n",
    "        for i in range(cases):\n",
    "            Case = {}\n",
    "            for j in NamePar:\n",
    "                #sampling the parameters space\n",
    "                sampling = np.random.choice(parameters[j])\n",
    "                Case[j] = sampling\n",
    "            #build the combination\n",
    "            Combinations.append(Case)\n",
    "\n",
    "        Combinations = np.array(Combinations)\n",
    "\n",
    "        #perform cross validation using Combinations\n",
    "\n",
    "        #divide data in folds\n",
    "        kf = KFold(n_splits=cv, random_state=1234, shuffle=True)\n",
    "\n",
    "        #array for the losses\n",
    "        loss = np.zeros(cases)\n",
    "\n",
    "        #loop over all the combinations\n",
    "        for i in range(cases):\n",
    "\n",
    "            print('Check the combination:',Combinations[i])\n",
    "            #loop over all the folds\n",
    "            fold=1\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                print('Fold', fold)\n",
    "                Xt, Xv = X_train[train_index], X_train[val_index]\n",
    "                Yt, Yv = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "                #convert to Tensor\n",
    "                Xt = torch.Tensor(Xt).float().view(-1, Xt.shape[1])\n",
    "                Yt = torch.LongTensor(Yt).squeeze()\n",
    "                Xv = torch.Tensor(Xv).float().view(-1, Xv.shape[1])\n",
    "                Yv = torch.LongTensor(Yv).squeeze()\n",
    "\n",
    "                #initialize the model with the first parameters\n",
    "                mod = model(list(Combinations[i][NamePar[0]]))\n",
    "                \n",
    "                #Training the network\n",
    "                #choose the correct optimizer\n",
    "                opt = optim.Adam(mod.parameters(), lr=Combinations[i]['optimizer__lr'], weight_decay=5e-4)\n",
    "\n",
    "                #training\n",
    "                _, l = Training(mod, opt, Combinations[i]['scheduler__gamma'], Combinations[i]['scheduler__cool'], epochs, \n",
    "                         Xt, Yt, Xv, Yv, verbose)\n",
    "\n",
    "                ### Summing the loss of each fold\n",
    "                loss[i] += l[-1]\n",
    "                fold += 1\n",
    "            print('Loss:', loss[i]/cv, '\\n')\n",
    "\n",
    "        #computing the average loss over the folds\n",
    "        loss = loss/cv\n",
    "        #the best combinations correspondes to minimum loss\n",
    "        best = Combinations[np.argmin(loss)]\n",
    "        \n",
    "        return Combinations, best\n",
    "\n",
    "    else: \n",
    "        print('The random search is not performed.')\n",
    "        return 0, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LdvWTEw0uQU"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE FINAL TRAINING\n",
    "\n",
    "def FinalTraining(Final,best,X_train,Y_train,epochs=10000):\n",
    "    if Final:\n",
    "        print('The best structure is:', best, '\\n')\n",
    "\n",
    "        #divide the training set into training and validation using scikit learn\n",
    "        Xt, Xv, Yt, Yv = train_test_split(X_train, Y_train, test_size=0.20, random_state=1234)\n",
    "        #convert to Tensor\n",
    "        Xt = torch.Tensor(Xt).float().view(-1, Xt.shape[1])\n",
    "        Yt = torch.LongTensor(Yt).squeeze()\n",
    "        Xv = torch.Tensor(Xv).float().view(-1, Xv.shape[1])\n",
    "        Yv = torch.LongTensor(Yv).squeeze()\n",
    "\n",
    "        #best combination of parameters\n",
    "\n",
    "        #model structure\n",
    "        net = Net(best['module__LN'])\n",
    "        #optimizer\n",
    "        opt = optim.Adam(net.parameters(), lr=best['optimizer__lr'], weight_decay=5e-4)\n",
    "        #train\n",
    "        tloss, vloss = Training(net, opt, best['scheduler__gamma'], best['scheduler__cool'], epochs, Xt, Yt, Xv, Yv, True)\n",
    "\n",
    "        #save the weights on cpu\n",
    "        if useCuda:\n",
    "            net.to('cpu')\n",
    "        #the state dictionary includes all the parameters of the network\n",
    "        net_state_dict = net.state_dict()\n",
    "        #save the state dict to a file\n",
    "        model_save_name = 'NetParameters.torch'\n",
    "        path = F\"{model_save_name}\" \n",
    "        torch.save(net_state_dict, path)\n",
    "        \n",
    "        return tloss, vloss\n",
    "    else: \n",
    "        print('The final training is not performed.')\n",
    "        return 0, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0OawnTd0uQW"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE ACCURACY\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def Accuracy(net,X,Y,Plot=True):\n",
    "    X = torch.Tensor(X).float().view(-1, X.shape[1])\n",
    "    Y = torch.LongTensor(Y).squeeze()\n",
    "\n",
    "    if useCuda:\n",
    "        X=X.cuda()\n",
    "        Y=Y.cuda()\n",
    "\n",
    "    Ypred = net.output(X)\n",
    "    temp = Ypred-Y\n",
    "    temp = temp.cpu().numpy()\n",
    "\n",
    "    #mask the array\n",
    "    temp[temp>0] = -1\n",
    "    temp[temp==0] = 1\n",
    "    temp[temp<0] = 0\n",
    "\n",
    "    #count the correct\n",
    "    correct = np.sum(temp)\n",
    "\n",
    "    if Plot:\n",
    "        if useCuda:\n",
    "            X=X.cpu().numpy()\n",
    "            Y=Y.cpu().numpy()\n",
    "            Ypred=Ypred.cpu().numpy()\n",
    "        #confusion matrix\n",
    "        cm = confusion_matrix(Y, Ypred)\n",
    "        #normalization\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #plot\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap='Blues', vmin=0, vmax=1)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               xticklabels=np.arange(0,10), yticklabels=np.arange(0,10),\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], '.2f'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.show()\n",
    "\n",
    "    return correct/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CIwydVK0uQY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "##### START THE COMPUTATION #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkcxIwlz0uQZ"
   },
   "outputs": [],
   "source": [
    "#DEFINE THE HYPERPARAMETERS\n",
    "\n",
    "def Params():\n",
    "    #Network architecture\n",
    "    #Number of layers\n",
    "    Layers = np.random.randint(1,4,size=50)\n",
    "\n",
    "    #Neurons per layer\n",
    "    Neurons =[]\n",
    "\n",
    "    for i in range(int(len(Layers)/2)):\n",
    "        m = np.random.choice([300,400,500,600]) \n",
    "        #divide the range\n",
    "        max = m\n",
    "        min = 100\n",
    "        step=(max-min)/(Layers[i])\n",
    "        min = m-step\n",
    "        N=[]\n",
    "        for j in range(Layers[i]):\n",
    "            N.append(np.random.randint(min,max))\n",
    "            max -= step\n",
    "            min -= step\n",
    "        Neurons.append(tuple(N))\n",
    "\n",
    "    for i in range(int(len(Layers)/2),len(Layers)):\n",
    "        m = np.random.choice([300,400,500,600]) \n",
    "        #divide the range\n",
    "        max = m\n",
    "        min = m-100\n",
    "        N=[]\n",
    "        for j in range(Layers[i]):\n",
    "            N.append(np.random.randint(min,max))\n",
    "        Neurons.append(tuple(N))\n",
    "\n",
    "    #Training parameters\n",
    "    #Learning rate\n",
    "    LearnigRate = [0.005,0.001,0.0005,0.0001]\n",
    "    #Gamma of decay\n",
    "    Gamma = [0.5,0.7,0.9]\n",
    "    #Cooldown\n",
    "    Cool =[0,50,100]\n",
    "\n",
    "    #FinalParameters\n",
    "    parameters = {'module__LN': Neurons,\n",
    "                  'optimizer__lr': LearnigRate,\n",
    "                  'scheduler__gamma': Gamma,\n",
    "                  'scheduler__cool': Cool\n",
    "                  }\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3705,
     "status": "ok",
     "timestamp": 1574281846573,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "4-jQjOJe0uQb",
    "outputId": "253e5291-fff0-499f-f606-d9cc3dc8c762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random search is not performed.\n"
     ]
    }
   ],
   "source": [
    "#PERFORM THE RANDOM SEARCH\n",
    "comb, best = RandomSearch(RC,Net,Params(),50,X_train,Y_train,4,2000,True)\n",
    "\n",
    "if RC:\n",
    "    print(comb,'\\n')\n",
    "    print('The best combination is', best, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78929,
     "status": "ok",
     "timestamp": 1574281921804,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "jdy9Kkak0uQf",
    "outputId": "3f037cf5-7296-452f-9649-6fc266e07a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final training is not performed.\n"
     ]
    }
   ],
   "source": [
    "#PERFORM THE FINAL TRAINING\n",
    "#results obtained through the cross validation\n",
    "best =  {'module__LN': (480, 132), 'optimizer__lr': 0.001, 'scheduler__gamma': 0.9, 'scheduler__cool': 0}\n",
    "\n",
    "#final training\n",
    "tloss, vloss = FinalTraining(Final,best,X_train,Y_train,10000)\n",
    "\n",
    "#plot the loss\n",
    "if Final:\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.semilogy(tloss, label='Train loss')\n",
    "    plt.semilogy(vloss, label='Val loss')\n",
    "    plt.xlabel('Epoch', fontsize=20)\n",
    "    plt.ylabel('Loss', fontsize=20)\n",
    "    plt.grid()\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.legend(prop=dict(size=18))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81501,
     "status": "ok",
     "timestamp": 1574281924382,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "ovXdlvbG0uQi",
    "outputId": "e4fe3314-c898-4635-8c42-29a8f7a32302"
   },
   "outputs": [],
   "source": [
    "#COMPUTE THE ACCURACY\n",
    "\n",
    "#LOAD THE NETWORK AND COMPUTE THE ACCURACY ON THE TEST SET\n",
    "#load the network\n",
    "#initialize the net\n",
    "net = Net(best['module__LN'])\n",
    "#load the state dict previously saved\n",
    "net_state_dict = torch.load('NetParameters.torch')\n",
    "  \n",
    "#update the network parameters\n",
    "net.load_state_dict(net_state_dict)\n",
    "\n",
    "if Acc:\n",
    "   \n",
    "    #compute the accuracy on training set\n",
    "    print('The accuracy on the training set is: %.3f' % Accuracy(net,X_train,Y_train))\n",
    "    #compute the accuracy on the test set\n",
    "    print('The accuracy on the test set is: %.3f' % Accuracy(net,X_test,Y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MJRwml00uQj"
   },
   "outputs": [],
   "source": [
    "#GET the weights\n",
    "\n",
    "#copy the dictionary containing the weights and the bias\n",
    "WeightsBias = net_state_dict.copy()\n",
    "#get the names of the weights and of the bias\n",
    "NameLayers = list(WeightsBias.keys())\n",
    "#take just the name of the weights\n",
    "WeightsName = [ x for x in NameLayers if 'bias' not in x ]\n",
    "\n",
    "#number of neurons in the hidden layers\n",
    "NN = []\n",
    "for i in range(len(WeightsName)):\n",
    "    NN.append(len(WeightsBias[WeightsName[i]]))\n",
    "    \n",
    "#RECEPTIVE FIELD \n",
    "def ReceptiveField(hn, netdict):\n",
    "\n",
    "    RFS = []\n",
    "    RFSLast = []\n",
    "\n",
    "    for k in range(hn):\n",
    "\n",
    "        RF = []\n",
    "        W = []\n",
    "\n",
    "        #first layer\n",
    "\n",
    "        #choiche on the neuron\n",
    "        n = np.random.choice(np.arange(1,NN[0]))\n",
    "        #matrix of weights from the input to the first hidden layer\n",
    "        mat = WeightsBias[WeightsName[0]]\n",
    "        #weights matrix\n",
    "        W.append(mat)\n",
    "        #receptive field\n",
    "        RF.append(mat[n,:].reshape(28,28))\n",
    "\n",
    "        for i in range(1, len(WeightsName)-1):\n",
    "            #choice on the neuron\n",
    "            n = np.random.choice(np.arange(1,NN[i]))\n",
    "            #matrix of weights from layer i-1 to the layer i\n",
    "            mat = WeightsBias[WeightsName[i]]\n",
    "            #store the weight matrix\n",
    "            W.append(mat)\n",
    "            #considering the weights from all the neurons in layer i-1 and the chosen neuron in layer i\n",
    "            Wj = mat[n,:]\n",
    "\n",
    "            prod=W[i-1]\n",
    "            for j in range(i-1,0,-1):\n",
    "                #compute the product among matrices\n",
    "                prod = np.matmul(prod,W[j-1])\n",
    "\n",
    "            #compute the final product\n",
    "            prod = np.matmul(Wj,prod)\n",
    "\n",
    "            #compute and store the receptive fields\n",
    "            RF.append(prod.reshape(28,28))\n",
    "        \n",
    "        RFS.append(RF)\n",
    "     \n",
    "    RF = []\n",
    "    \n",
    "    for i in range(10):    \n",
    "        #matrix of weight last hidden layer\n",
    "        prod = WeightsBias[WeightsName[-2]]\n",
    "        for j in range(len(WeightsName)-3,-1,-1):\n",
    "            mat = WeightsBias[WeightsName[j]]\n",
    "            #compute the product among matrices\n",
    "            prod = np.matmul(prod,mat)\n",
    "            \n",
    "        #considering the weights from all the neurons in layer i-1 and the chosen neuron in the last layer \n",
    "        mat = WeightsBias[WeightsName[-1]]   \n",
    "        Wi = mat[i,:]   \n",
    "        #compute the final product\n",
    "        prod = np.matmul(Wi,prod)\n",
    "        #compute and store the receptive fields\n",
    "        RF.append(prod.reshape(28,28))\n",
    "        \n",
    "    RFSLast.append(RF)\n",
    "\n",
    "    return RFS, RFSLast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83253,
     "status": "ok",
     "timestamp": 1574281926144,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "how2AkkR0uQl",
    "outputId": "2b54465f-33f2-4448-8fba-7dbf8dac337e"
   },
   "outputs": [],
   "source": [
    "#COMPUTE THE RECEPTIVE FIELDS\n",
    "\n",
    "if RF:\n",
    "    #compute the receptive fields\n",
    "    RFS, RFSLast = ReceptiveField(4, net_state_dict)\n",
    "    #plot the receptive fields\n",
    "    for layer in range(len(RFS[0])):\n",
    "        (fig, subplots) = plt.subplots(2, 2, figsize=(8, 8))\n",
    "        fig.suptitle(\"Layer=%i\" % (layer+1), fontsize=15)\n",
    "        case = 0 \n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                ax = subplots[j][i]\n",
    "                im = ax.imshow(RFS[case][layer], cmap='gray')\n",
    "                case += 1\n",
    "                \n",
    "    #plot the output layer\n",
    "    (fig, subplots) = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    fig.suptitle(\"Last layer\", fontsize=15)\n",
    "    neuron = 0 \n",
    "    for j in range(2):\n",
    "        for i in range(5):\n",
    "            ax = subplots[j][i]\n",
    "            im = ax.imshow(RFSLast[0][neuron], cmap='gray')\n",
    "            ax.set_title('Neuron %i' %(neuron))\n",
    "            neuron += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YjtgNgdeIYB"
   },
   "outputs": [],
   "source": [
    "#IMPROVE THE FEATURE VISUALIZATION\n",
    "\n",
    "\n",
    "def Activation(Net,ChosenLayer,Input):\n",
    "    #compute the output of first layer\n",
    "    if ChosenLayer == 1:\n",
    "        return Net.network.act1(Net.network.net1(Input))\n",
    "    #compute the output of second layer\n",
    "    if ChosenLayer == 2:\n",
    "        return Net.network.act2(Net.network.net2(Net.network.act1(Net.network.net1(Input))))\n",
    "    #compute the output of third layer\n",
    "    if ChosenLayer == 3:\n",
    "        return Net.network.net3(Net.network.act2(Net.network.net2(Net.network.act1(Net.network.net1(Input)))))\n",
    "    \n",
    "\n",
    "def FeatureVisualization(cL, cN, epochs,lrate, Net):\n",
    "    #initilize a matrix with zeros\n",
    "    mat = torch.zeros(784, requires_grad=True) \n",
    "    #define the optimizer\n",
    "    optimizer = torch.optim.Adam([mat], lr=lrate, weight_decay=5e-4)\n",
    "\n",
    "    #train\n",
    "    for num_ep in range(epochs):  \n",
    "        optimizer.zero_grad()\n",
    "        #define the act as minus act to obtain a gradient ascent\n",
    "        act = -Activation(Net,cL,mat)[cN] \n",
    "        act.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10706,
     "status": "ok",
     "timestamp": 1574282116055,
     "user": {
      "displayName": "Marino Braghetto",
      "photoUrl": "",
      "userId": "02551736165510158038"
     },
     "user_tz": -60
    },
    "id": "25U2MJWpUA_4",
    "outputId": "fb9ce499-1637-493e-aa59-68f32cd4e839"
   },
   "outputs": [],
   "source": [
    "if FV:\n",
    "    #compute and plot for hidden layers\n",
    "    for layer in range(1,3):\n",
    "        (fig, subplots) = plt.subplots(2, 2, figsize=(8, 8))\n",
    "        fig.suptitle(\"Layer=%i\" % (layer+1), fontsize=15)\n",
    "        case = 0 \n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                n = np.random.choice(np.arange(1,NN[layer]))\n",
    "                F = FeatureVisualization(layer,n,500,0.1,net)\n",
    "                F = F.cpu().detach().numpy()\n",
    "                ax = subplots[j][i]\n",
    "                im = ax.imshow(F.reshape(28,28), cmap='gray')\n",
    "\n",
    "    #plot the output layer\n",
    "    (fig, subplots) = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    fig.suptitle(\"Last layer\", fontsize=25)\n",
    "    n = 0 \n",
    "    for j in range(2):\n",
    "        for i in range(5):\n",
    "            F = FeatureVisualization(3,n,500,0.1,net)\n",
    "            F = F.cpu().detach().numpy()\n",
    "            ax = subplots[j][i]\n",
    "            im = ax.imshow(F.reshape(28,28), cmap='gray')\n",
    "            ax.set_title('Neuron %i' %(n), fontsize=15)\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xABPvMYwAgOp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2-Braghetto-CODE.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
